---
title: Evaluating Foundation Models Shouldn’t Be Fragmented
excerpt: Introducing the AI Balance Sheet — a multidimensional framework for foundation model governance and accountability.
layout: single
author_profile: true
---

Foundation models are shaping everything from content moderation to clinical tools — but our methods for evaluating them are still siloed. Bias audits here, carbon metrics there, business KPIs somewhere else.

At NYU’s QLab, I co-developed the **AI Balance Sheet** — a framework to evaluate foundation models across technical, ethical, business, and environmental dimensions. It’s structured like a financial balance sheet: assets include transparency, inclusivity, and utility; liabilities include opacity, misinformation, and extractive labor.

We synthesized stakeholder interviews, regulatory guidelines, and 30+ model audits into a single evaluative structure. Key insight: developers often measure what’s easy, not what’s important — leaving institutions blind to tradeoffs that matter.

Working on this taught me how to align AI accountability with real-world incentives. It also showed me that thoughtful frameworks don’t need to be complex — they need to be legible across disciplines and useful in practice.